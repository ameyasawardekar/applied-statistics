{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyasawardekar/applied-statistics/blob/main/Copy_of_Applied_Statistics_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Purchase Behavior Analysis using Descriptive Statistics"
      ],
      "metadata": {
        "id": "XVRRli7RVQFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement"
      ],
      "metadata": {
        "id": "jfhbp8ZDB7If"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç **Problem Statement**:\n",
        "\n",
        "Welcome to the Probability and Statistics project! üìäüîç In this exciting journey, you'll get the chance to apply the concepts you've learned in probability theory and statistics to analyze a real-world dataset. This project is your opportunity to dive deep into the world of data analysis and gain practical experience with the tools and techniques you've been learning. üöÄ\n",
        "\n",
        "üéØ **Objective**:\n",
        "\n",
        "Your mission is to analyze the provided dataset containing customer information and purchasing behavior to make informed decisions. Your goal is to identify patterns, trends, and correlations that will help your company optimize its marketing efforts and increase offer acceptance rates. üéâ"
      ],
      "metadata": {
        "id": "EB1yLJOSV1gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##About the Dataset"
      ],
      "metadata": {
        "id": "C6I6fCk2B4W-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here's the link to the [dataset](https://docs.google.com/spreadsheets/d/12ln9iTNcVNOMYi_AU-OczKpa_KIP8XyVbsjk81Na8Yk/edit?usp=sharing)\n",
        "\n",
        "\n",
        "This data was gathered during last year's campaign.\n",
        "Data description is as follows;\n",
        "\n",
        "1. Response (target) - 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
        "1. ID - Unique ID of each customer\n",
        "1. Year_Birth - Age of the customer\n",
        "1. Complain - 1 if the customer complained in the last 2 years\n",
        "1. Dt_Customer - date of customer's enrollment with the company\n",
        "1. Education - customer's level of education\n",
        "1. Marital - customer's marital status\n",
        "1. Kidhome - number of small children in customer's household\n",
        "1. Teenhome - number of teenagers in customer's household\n",
        "1. Income - customer's yearly household income\n",
        "1. MntFishProducts - the amount spent on fish products in the last 2 years\n",
        "1. MntMeatProducts - the amount spent on meat products in the last 2 years\n",
        "1. MntFruits - the amount spent on fruits products in the last 2 years\n",
        "1. MntSweetProducts - amount spent on sweet products in the last 2 years\n",
        "1. MntWines - the amount spent on wine products in the last 2 years\n",
        "1. MntGoldProds - the amount spent on gold products in the last 2 years\n",
        "1. NumDealsPurchases - number of purchases made with discount\n",
        "1. NumCatalogPurchases - number of purchases made using catalog (buying goods to be shipped through the mail)\n",
        "1. NumStorePurchases - number of purchases made directly in stores\n",
        "1. NumWebPurchases - number of purchases made through the company's website\n",
        "1. NumWebVisitsMonth - number of visits to company's website in the last month\n",
        "1. Recency - number of days since the last purchase\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E_yV1UBOAu7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 1 - Basic CleanUp\n",
        "\n",
        "- **Clean and preprocess the dataset (handling missing values, data types, etc.).**\n",
        "\n",
        "- **Analyze the distribution of customer demographics (age, education, marital status) using descriptive statistics and visualizations.**"
      ],
      "metadata": {
        "id": "HNjRqBCzXQww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Deliverables**:\n",
        "\n",
        "- **Cleaned and Preprocessed Dataset**:\n",
        "\n",
        "  Provide a detailed report on the steps taken to handle missing values, including imputation methods used if applicable.\n",
        "  Document the process of ensuring consistent data types for each variable, addressing any inconsistencies.\n",
        "\n",
        "- **Summary of Basic Statistics**:\n",
        "\n",
        "  Present calculated statistics such as mean, median, variance, and standard deviation for each relevant numerical variable.\n",
        "  Include a concise table or summary showcasing these measures for easy reference."
      ],
      "metadata": {
        "id": "AIUm4NpNX4vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "W0ZoztBXfITs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading the dataset (I upload dataset on Github and get link)\n",
        "data_path = \"Copy_of_Applied_Statistics_Project.ipynb.csv\"\n",
        "data = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "0qzQcj93gi76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "9e4306ca-1cb1-4ebf-d02f-37593453d9b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Copy_of_Applied_Statistics_Project.ipynb.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-70e260c3d3fa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the dataset (I upload dataset on Github and get link)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Copy_of_Applied_Statistics_Project.ipynb.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Copy_of_Applied_Statistics_Project.ipynb.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l6GM0rghC4p",
        "outputId": "65afba96-7c46-4fe4-c863-22b98a73f4d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2 - Descriptive Statistics üìä\n",
        "\n",
        "- **Calculate measures of central tendency (mean, median, mode) and measures of dispersion (variance, standard deviation) for key variables. Identify and handle outliers if necessary.**\n"
      ],
      "metadata": {
        "id": "bDza2Cu0YpE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables**:\n",
        "\n",
        "- **Descriptive statistics that reveal the central tendencies, variations, and potential outliers in the dataset.**:\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "pGrBYXGWZtYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3 - Probability Distributions üé≤\n",
        "\n",
        "- **Identify variables that could follow specific probability distributions (e.g., Binomial, Normal). Calculate probabilities and expected values based on these distributions.**\n",
        "\n"
      ],
      "metadata": {
        "id": "GCB3OLxXaSCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables**:\n",
        "\n",
        "- **Determination of suitable probability distributions for relevant variables and corresponding calculated probabilities and expected values.**:\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "kgjtExiJay2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Insights and Customer Segmentation üìà\n",
        "\n",
        "- **Explore relationships between customer characteristics and spending habits. Segment customers based on their behaviors and characteristics.**"
      ],
      "metadata": {
        "id": "ZSHZP8wgcIKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables**:\n",
        "\n",
        "- **Key insights regarding relationships between variables and distinct customer segments based on behaviors.**\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "1UYOJxazcRi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Conclusion and Recommendations\n",
        "\n",
        "- **Create clear visualizations to showcase your findings. Use insights to make recommendations for the company based on your analysis.**"
      ],
      "metadata": {
        "id": "Fv6iVJbgiwf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deliverables**:\n",
        "\n",
        "- **Well-designed visualizations that visually represent your insights and actionable recommendations based on customer behavior analysis.**"
      ],
      "metadata": {
        "id": "-z5hEuOejQjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus Task - Geogebra Experiment\n",
        "\n"
      ],
      "metadata": {
        "id": "Fib_ksA9jmii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the link to an intriguing GeoGebra experiment: [GeoGebra Experiment Link](https://www.geogebra.org/m/LZbwMZtJ)\n",
        "\n",
        "This experiment lets you simulate coin flips as per your preferences and specifications!\n",
        "\n",
        "Your task involves recording a video where you'll explain the concept of the **Law of Large Numbers** using this experiment. Dive further into the experience by adjusting the number of coins and exploring varying coin biases. ü™ôüìπüîç"
      ],
      "metadata": {
        "id": "olsEhR8RjsIF"
      }
    }
  ]
}